custom:
  basic-cluster-props: &basic-cluster-props
    spark_version: "12.2.x-scala2.12"
    node_type_id: "Standard_F8"
    spark_conf:
      spark.databricks.delta.preview.enabled: 'true'
    runtime_engine: STANDARD

  basic-auto-scale-props: &basic-auto-scale-props
    autoscale:
      min_workers: 2
      max_workers: 8

  basic-autoscale-cluster: &basic-autoscale-cluster
    new_cluster:
      <<: # merge these two maps and place them here.
        - *basic-cluster-props
        - *basic-auto-scale-props

environments:
  default:
    workflows:
      - name: "dummy_ingestion_refine_to_conform"
        access_control_list:
          - service_principal_name: "service-principal://azr_mq_aws_to_azure_refine_dev"
            permission_level: "IS_OWNER"
        job_clusters:
          - job_cluster_key: "demo_job_key"
            <<: *basic-autoscale-cluster
        git_source:
          git_url: https://github.com/sudhanshu16/sudhanshu_demo.git
          git_provider: "Github"
          git_branch: #{Build.SourceBranchName}#            
        tasks:
          - task_key: "log-execution-start"
            deployment_config:
              no_package: true
            job_cluster_key: "demo_job_key"
            notebook_task:
              notebook_path: "azure_aws_ingestion/notebooks/caveau-refine-ingestion-log"    
              base_parameters:
                run_id: "{{parent_run_id}}"
                log_event: "start"    
                # catalog: "mq_gmdf_dev"
                # database: "refine"
                # global_log_table: "global_execution"
                # refine_log_table: "ref_exection"
                systems: '[{"launch":"batch","r_src_id": 9,"mode": "as_AWS"}]'
          # - task_key: "execution"
          #   deployment_config:
          #     no_package: true
          #   depends_on:
          #     - task_key: "log-execution-start"
          #   job_cluster_key: "demo_job_key"
          #   notebook_task:
          #     notebook_path: "ci-cd/Untitled Notebook 2023-10-05 13_50_22.py"
          #     base_parameters:
          #       run_id: "{{parent_run_id}}"
          #       systems: '[{"launch":"batch","r_src_id": 9,"mode": "as_AWS"}]'                
          # - task_key: "log-execution-end"
          #   deployment_config:
          #     no_package: true
          #   depends_on:
          #     - task_key: "execution"
          #   job_cluster_key: "demo_job_key"
          #   notebook_task:
          #     notebook_path: "ci-cd/Untitled Notebook 2023-10-05 13_50_22.py"     
          #     base_parameters:
          #       run_id: "{{parent_run_id}}"
          #       log_event: "end"    
          #       catalog: "mq_gmdf_dev"
          #       database: "refine"
          #       global_log_table: "global_execution"
          #       refine_log_table: "ref_execution"     
          #       systems: '[{"launch":"batch","r_src_id": 9,"mode": "as_AWS"}]'         
